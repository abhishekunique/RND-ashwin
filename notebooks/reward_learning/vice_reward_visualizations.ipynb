{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import math\n",
    "import skimage\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dir = '/home/justinvyu/ray_results'\n",
    "universe = 'gym'\n",
    "domain = 'Point2D'\n",
    "task = 'Maze-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(common_dir, universe, domain, task)\n",
    "exps = sorted(list(glob.iglob(os.path.join(base_path, '*'))))\n",
    "for i, exp in enumerate(exps):\n",
    "    print(f'{i} \\t {exp.replace(base_path, \"\")}')\n",
    "    \n",
    "exp_choice = int(input('\\n Which experiment do you want to analyze? (ENTER A NUMBER) \\t'))\n",
    "\n",
    "exp_path = exps[exp_choice]\n",
    "print('\\n')\n",
    "seeds = sorted(list(glob.iglob(os.path.join(exp_path, '*'))))\n",
    "seeds = [seed for seed in seeds if os.path.isdir(seed)]\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f'{i} \\t {seed.replace(exp_path, \"\")}')\n",
    "    \n",
    "# TODO: Extend to analyzing all seeds\n",
    "seed_choice = int(input('\\n Which seed do you want to analyze? (ENTER A NUMBER) \\t'))\n",
    "\n",
    "seed_path = seeds[seed_choice]\n",
    "\n",
    "print('PATH:\\n', seed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_to_analyze = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(seed_path, f'checkpoint_{checkpoint_to_analyze}/checkpoint.pkl'), 'rb') as f:\n",
    "    checkpoint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reward Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_clf = checkpoint['reward_classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = checkpoint['training_environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = train_env.unwrapped._get_obs()['state_desired_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = train_env.n_bins + 1\n",
    "\n",
    "for i in range(n_bins):\n",
    "    for j in range(n_bins):\n",
    "        obs = np.eye(n_bins)[np.array([i, j])].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "obs_space = train_env.unwrapped.observation_space['state_observation']\n",
    "xs = np.linspace(obs_space.low[0], obs_space.high[0], n_samples)\n",
    "ys = np.linspace(obs_space.low[1], obs_space.high[1], n_samples)\n",
    "\n",
    "xys = np.meshgrid(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_vals = np.array(xys).transpose(1, 2, 0).reshape((n_samples * n_samples, 2))\n",
    "grid_vals = np.array([np.eye(n_bins)[train_env.unwrapped._discretize_observation(grid_val)].flatten() for grid_val in grid_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = reward_clf.predict(grid_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "from matplotlib.patches import Rectangle\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.contourf(xys[0], xys[1], rewards.reshape(xys[0].shape), levels=20)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "if task == 'BoxWall-v1':\n",
    "    currentAxis = plt.gca()\n",
    "    currentAxis.add_patch(Rectangle((-2, -2), 4, 4,\n",
    "                          alpha=1, fill=None, linewidth=4))\n",
    "\n",
    "plt.scatter(*target_pos, marker='*', s=250, color='white')\n",
    "plt.title(f'VICE Reward for {domain + task} Task @ Checkpoint #{checkpoint_to_analyze}\\n'\n",
    "          + f'Target Pos: {target_pos}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot All Checkpoints at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vice_reward(clf, train_env, n_samples=50):\n",
    "    obs_space = train_env.observation_space['state_observation']\n",
    "    xs = np.linspace(obs_space.low[0], obs_space.high[0], n_samples)\n",
    "    ys = np.linspace(obs_space.low[1], obs_space.high[1], n_samples)\n",
    "\n",
    "    xys = np.meshgrid(xs, ys)\n",
    "    grid_vals = np.array(xys).transpose(1, 2, 0).reshape((n_samples * n_samples, 2))\n",
    "    \n",
    "    rewards = clf.predict(grid_vals)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.contourf(xys[0], xys[1], rewards.reshape(xys[0].shape), levels=300)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    target_pos = train_env.unwrapped._get_obs()['state_desired_goal']\n",
    "\n",
    "    if task == 'BoxWall-v1':\n",
    "        currentAxis = plt.gca()\n",
    "        currentAxis.add_patch(Rectangle((-2, -2), 4, 4,\n",
    "                              alpha=1, fill=None, linewidth=4))\n",
    "\n",
    "    plt.scatter(*target_pos, marker='*', s=250, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(imgs, labels=None):\n",
    "    n_images = len(imgs)\n",
    "    n_columns = np.sqrt(n_images)\n",
    "    n_rows = np.ceil(n_images / n_columns) + 1\n",
    "    plt.figure(figsize=(5 * n_columns, 5 * n_rows))\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        if labels is not None:\n",
    "            plt.title(labels[i], fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = list(glob.iglob(os.path.join(seed_path, 'checkpoint_*')))\n",
    "# Sort by the checkpoint number at the end\n",
    "checkpoint_paths = sorted(checkpoint_paths, key=lambda s: int(s.split(\"_\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots = len(checkpoint_paths)\n",
    "n_columns = int(np.sqrt(n_plots) + 1)\n",
    "n_rows = np.ceil(n_plots / n_columns)\n",
    "plt.figure(figsize=(5 * n_columns, 5 * n_rows))\n",
    "\n",
    "for i, path in enumerate(checkpoint_paths):\n",
    "    with open(os.path.join(path, 'checkpoint.pkl'), 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "    reward_clf = checkpoint['reward_classifier']\n",
    "    train_env = checkpoint['training_environment']\n",
    "    plt.subplot(n_rows, n_columns, i+1, aspect=1)\n",
    "    plot_vice_reward(reward_clf, train_env)\n",
    "    plt.title(int(path.split(\"_\")[-1]), fontsize=20)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Visitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from softlearning.replay_pools.utils import get_replay_pool_from_variant\n",
    "\n",
    "replay_pool = None\n",
    "train_env = None\n",
    "\n",
    "for i, path in enumerate(checkpoint_paths):\n",
    "    if replay_pool is None:\n",
    "        with open(os.path.join(path, 'checkpoint.pkl'), 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "        variant = checkpoint['variant']\n",
    "        train_env = checkpoint['training_environment']\n",
    "        replay_pool = get_replay_pool_from_variant(variant, train_env)\n",
    "        \n",
    "    replay_pool_path = os.path.join(path, 'replay_pool.pkl')\n",
    "    replay_pool.load_experience(replay_pool_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_rows = replay_pool.data[('observations', 'state_observation')].any(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitations = replay_pool.data[('observations', 'state_observation')][non_zero_rows]\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-4, 4)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.imshow(train_env.render('rgb_array'),\n",
    "           extent=(-4, 4, -4, 4),\n",
    "           origin='lower',\n",
    "           alpha=0.25,\n",
    "           zorder=3,\n",
    "           interpolation='nearest')\n",
    "\n",
    "plt.scatter(visitations[:, 0], visitations[:, 1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Goal Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/justinvyu/dev/vice/goal_classifier/pointmass_nowalls/bottom_middle/positives.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(data['state_observation'][:,0], data['state_observation'][:,1], s=5)\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Ground Truth Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    'state_achieved_goal': grid_vals,\n",
    "    'state_desired_goal': np.full(grid_vals.shape, fill_value=2)\n",
    "}\n",
    "train_env.unwrapped.reward_type = 'sparse'\n",
    "gtr = train_env.unwrapped.compute_rewards(None, feed_dict)\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.contourf(xys[0], xys[1], gtr.reshape(xys[0].shape))\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "if task == 'BoxWall-v1':\n",
    "    currentAxis = plt.gca()\n",
    "    currentAxis.add_patch(Rectangle((-2, -2), 4, 4,\n",
    "                          alpha=1, fill=None, linewidth=4))\n",
    "\n",
    "plt.title(f'Ground Truth Reward for {domain + task} Task @ Checkpoint #{checkpoint_to_analyze}')\n",
    "\n",
    "plt.scatter(*target_pos, marker='*', s=250, color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qs Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_to_analyze = 100\n",
    "checkpoint_dir = os.path.join(seed_path, f'checkpoint_{checkpoint_to_analyze}')\n",
    "\n",
    "with open(os.path.join(checkpoint_dir, 'checkpoint.pkl'), 'rb') as f:\n",
    "    checkpoint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = checkpoint['variant']\n",
    "env = checkpoint['training_environment']\n",
    "target_pos = env.unwrapped._get_obs()['state_desired_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from softlearning.value_functions.utils import get_Q_function_from_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = get_Q_function_from_variant(variant, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, Q in enumerate(Qs):\n",
    "    weights_path = os.path.join(checkpoint_dir, f'Qs_{i}')\n",
    "    Q.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_action_samples = 20\n",
    "sample_actions = np.vstack([env.action_space.sample() for _ in range(n_action_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "obs_space = env.observation_space['state_observation']\n",
    "xs = np.linspace(obs_space.low[0], obs_space.high[0], n_samples)\n",
    "ys = np.linspace(obs_space.low[1], obs_space.high[1], n_samples)\n",
    "\n",
    "xys = np.meshgrid(xs, ys)\n",
    "grid_vals = np.array(xys).transpose(1, 2, 0).reshape((n_samples * n_samples, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_estimates = []\n",
    "for pos in grid_vals:\n",
    "    value_estimates.append(\n",
    "        np.min([Q.predict([sample_actions,\n",
    "                        np.repeat(pos, n_action_samples).reshape((n_action_samples, -1))])\n",
    "             for Q in Qs])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "from matplotlib.patches import Rectangle\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.contourf(xys[0], xys[1], np.array(value_estimates).reshape(xys[0].shape))\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "if task == 'BoxWall-v1':\n",
    "    currentAxis = plt.gca()\n",
    "    currentAxis.add_patch(Rectangle((-2, -2), 4, 4,\n",
    "                          alpha=1, fill=None, linewidth=4))\n",
    "\n",
    "plt.scatter(*target_pos, marker='*', s=250, color='white')\n",
    "plt.title(f'Value function estimates for {domain + task} Task @ Checkpoint #{checkpoint_to_analyze}\\n'\n",
    "          + f'Target Pos: {target_pos}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(grid_vals[0], n_action_samples).reshape((n_action_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
