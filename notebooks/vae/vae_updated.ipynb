{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "import skimage\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/kun1/users/justinvyu/data/fixed_data.pkl'\n",
    "import gzip\n",
    "import pickle\n",
    "with gzip.open(path, 'rb') as f:\n",
    "    images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images, unnormalized_images = images[:300000], images[300000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images.shape, unnormalized_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_images_0 = skimage.util.img_as_ubyte(normalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_images_1 = unnormalized_images.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fixed_images_0[15000])\n",
    "plt.imshow(fixed_images_1[15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_dataset = np.stack([fixed_images_0, fixed_images_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fixed_dataset[599999])\n",
    "fixed_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "with gzip.open('/root/nfs/kun1/users/justinvyu/data/fixed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(fixed_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(fixed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = fixed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/eval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = images.shape[0]\n",
    "split_index = int(0.1 * num_images)\n",
    "train_images = images[split_index:]\n",
    "test_images = images[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def train_generator():\n",
    "    for image in train_images:\n",
    "        yield image\n",
    "\n",
    "def test_generator():\n",
    "    for image in test_images:\n",
    "        yield image\n",
    "        \n",
    "train_dataset = tf.data.Dataset.from_generator(train_generator, tf.uint8).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_generator(test_generator, tf.uint8).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from softlearning.models.vae import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the optimizer + ELBO loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "\n",
    "    # Cross entropy reconstruction loss assumes that the pixels\n",
    "    # are all independent Bernoulli r.v.s\n",
    "    # Need to preprocess the label, so the output will be normalized.\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=x_logit, labels=model.preprocess(x))\n",
    "    # Sum across all pixels (row/col) + channels\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    \n",
    "    # Calculate the KL divergence (difference between log of unit normal prior and posterior)\n",
    "    logpz = log_normal_pdf(z, 0., 0.) # Prior PDF\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar) # Posterior\n",
    "    \n",
    "    reconstruction_loss = logpx_z\n",
    "    kl_divergence = logpz - logqz_x\n",
    "    \n",
    "    beta = 1.0\n",
    "    loss = reconstruction_loss + beta * kl_divergence\n",
    "    \n",
    "#     return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "    return -tf.reduce_mean(loss)\n",
    "\n",
    "@tf.function\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "latent_dim = 4\n",
    "num_examples_to_generate = 16\n",
    "image_shape = (32, 32, 3)\n",
    "\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "vae = VAE(image_shape=image_shape, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.encoder.summary()\n",
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, title=''):\n",
    "    num_images = images.shape[0]\n",
    "    rows = int(np.sqrt(num_images))\n",
    "    cols = num_images // rows\n",
    "    plt.figure(figsize=(rows, cols))\n",
    "    plt.title(title)\n",
    "    print(title)\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i, ...])\n",
    "    plt.show()\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model.sample(test_input)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, :])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('/home/justinyu/Developer/softlearning/notebooks/vae_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(vae, 0, random_vector_for_generation)\n",
    "elbo_history = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        compute_apply_gradients(vae, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if epoch % 25 == 0:\n",
    "        # Save weights\n",
    "        vae.encoder.save_weights('/home/justinyu/Developer/softlearning/notebooks/vae_weights/invisible_claw_encoder_weights_4.h5')\n",
    "        vae.decoder.save_weights('/home/justinyu/Developer/softlearning/notebooks/vae_weights/invisible_claw_decoder_weights_4.h5')\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        loss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            loss(compute_loss(vae, test_x))\n",
    "        elbo = -loss.result()\n",
    "        display.clear_output(wait=False)\n",
    "        print('Epoch: {}, Test set ELBO: {}, '\n",
    "              'time elapse for current epoch {}'.format(epoch, elbo, end_time - start_time))\n",
    "        elbo_history.append(elbo)\n",
    "        generate_and_save_images(\n",
    "            vae, epoch, random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing ground truth vs. reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 64\n",
    "eval_images = test_images[:n]\n",
    "plot_images(eval_images, title='Ground truth images')\n",
    "reconstructions = vae(eval_images)\n",
    "plot_images(np.array(reconstructions), title='VAE Reconstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.encoder.save_weights('/home/justinyu/Developer/softlearning/notebooks/vae_weights/invisible_claw_encoder_weights_4_final.h5')\n",
    "vae.decoder.save_weights('/home/justinyu/Developer/softlearning/notebooks/vae_weights/invisible_claw_decoder_weights_4_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vae = VAE(image_shape=(32, 32, 3), latent_dim=16)\n",
    "path = '/home/justinyu/Developer/softlearning/softlearning/models/vae_weights'\n",
    "encoder_path = os.path.join(path, 'invisible_claw_encoder_weights.h5')\n",
    "decoder_path = os.path.join(path, 'invisible_claw_decoder_weights.h5')\n",
    "loaded_vae.encoder.load_weights(encoder_path)\n",
    "loaded_vae.decoder.load_weights(decoder_path)\n",
    "loaded_reconstructions = loaded_vae(eval_images)\n",
    "plot_images(np.array(loaded_reconstructions), title='Loaded VAE Reconstructions')\n",
    "loaded_encodings = loaded_vae.encode(eval_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vae.get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fn = '/nfs/kun1/users/justinvyu/data/checkpoint.pkl'\n",
    "replay_pool_fn = '/nfs/kun1/users/justinvyu/data/replay_pool.pkl'\n",
    "import pickle\n",
    "import gzip\n",
    "with open(checkpoint_fn, 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "    \n",
    "with gzip.open(replay_pool_fn, 'rb') as f:\n",
    "    replay_pool = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder_weights = checkpoint['policy_weights'][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vae.encoder.set_weights(vae_encoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_reconstructions = loaded_vae(eval_images)\n",
    "plot_images(np.array(loaded_reconstructions), title='Loaded VAE Reconstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_pool_images = replay_pool['observations']['pixels']\n",
    "random_indices = np.random.randint(replay_pool_images.shape[0], size=100)\n",
    "eval_replay_pool = replay_pool_images[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_reconst = loaded_vae(eval_replay_pool)\n",
    "plot_images(eval_replay_pool)\n",
    "plot_images(np.array(eval_reconst), title='Loaded VAE Reconstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_encodings = vae.encode(eval_images)\n",
    "np.set_printoptions(precision=3)\n",
    "np.array(eval_encodings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded =[ 2.0327365 , -0.48694006,  1.119025  , -0.08618406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_encoding = vae.encode(images[10000][None])[0]\n",
    "example_encoding\n",
    "print(example_encoding)\n",
    "plt.imshow(vae.decode(np.array([example_encoding]), apply_sigmoid=True)[0])\n",
    "plt.show()\n",
    "plt.imshow(vae.decode(np.array([test_encoded]), apply_sigmoid=True)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
